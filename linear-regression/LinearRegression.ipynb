{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"D:\\spark-3.2.1-bin-hadoop3.2\")\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f6f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"lr_exmaple\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32948f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"data/dummy_data.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae10f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: string (nullable = true)\n",
      " |-- lpep_dropoff_datetime: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199557f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ffba697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'lpep_pickup_datetime',\n",
       " 'lpep_dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7ed17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import random\n",
    "# data_modified = data.select(\"*\", (F.col(\"fare_amount\") - F.col(\"total_amount\")).alias(\"weather\"))\n",
    "# data_modified.columns\n",
    "data_modified = data.withColumn(\"weather\", F.round(F.rand() * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6262c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+-------+-------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|weather|trip_duration|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+-------+-------------+\n",
      "|       2| 2019-12-18 15:52:30|  2019-12-18 15:54:39|                 N|         1|         264|         264|              5|          0.0|        3.5|  0.5|    0.5|      0.01|         0.0|     null|                  0.3|        4.81|           1|        1|                 0.0|    2.0|        129.0|\n",
      "|       2| 2020-01-01 00:45:58|  2020-01-01 00:56:39|                 N|         5|          66|          65|              2|         1.28|       20.0|  0.0|    0.0|      4.06|         0.0|     null|                  0.3|       24.36|           1|        2|                 0.0|    4.0|        641.0|\n",
      "|       2| 2020-01-01 00:41:38|  2020-01-01 00:52:49|                 N|         1|         181|         228|              1|         2.47|       10.5|  0.5|    0.5|      3.54|         0.0|     null|                  0.3|       15.34|           1|        1|                 0.0|    5.0|        671.0|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+-------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.types import DoubleType\n",
    "def getTripDuration(datetime_start, datetime_end):\n",
    "    try:\n",
    "        result = (datetime.strptime(datetime_end, \"%Y-%m-%d %H:%M:%S\") - datetime.strptime(datetime_start, \"%Y-%m-%d %H:%M:%S\")).total_seconds()\n",
    "        return result\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "tripDurationFunction = F.udf(getTripDuration, DoubleType())\n",
    "# datetime_object = datetime.strptime(\"2019-12-18 15:52:30\", \"%Y-%m-%d %H:%M:%S\")\n",
    "# datetime_object2 = datetime.strptime(\"2019-12-18 15:54:39\", \"%Y-%m-%d %H:%M:%S\")\n",
    "# print(f\"This is datetime: {(datetime_object2 - datetime_object).total_seconds()}\")\n",
    "data_modified = data_modified.withColumn(\"trip_duration\", tripDurationFunction(\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\"))\n",
    "data_modified.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c816abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'lpep_pickup_datetime',\n",
       " 'lpep_dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge',\n",
       " 'weather',\n",
       " 'trip_duration']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_modified.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21c6e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['PULocationID','DOLocationID','passenger_count','trip_distance','fare_amount','extra','mta_tax','tip_amount','tolls_amount','improvement_surcharge', 'total_amount','payment_type','trip_type','congestion_surcharge','weather','trip_duration'], outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08643041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime='2019-12-18 15:52:30', lpep_dropoff_datetime='2019-12-18 15:54:39', store_and_fwd_flag='N', RatecodeID=1, PULocationID=264, DOLocationID=264, passenger_count=5, trip_distance=0.0, fare_amount=3.5, extra=0.5, mta_tax=0.5, tip_amount=0.01, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=4.81, payment_type=1, trip_type=1, congestion_surcharge=0.0, weather=2.0, trip_duration=129.0, features=DenseVector([264.0, 264.0, 5.0, 0.0, 3.5, 0.5, 0.5, 0.01, 0.0, 0.3, 4.81, 1.0, 1.0, 0.0, 2.0, 129.0]))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = assembler.transform(data_modified)\n",
    "output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d34c5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select(\"features\", \"total_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbcc3d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|total_amount|\n",
      "+--------------------+------------+\n",
      "|[264.0,264.0,5.0,...|        4.81|\n",
      "|[66.0,65.0,2.0,1....|       24.36|\n",
      "|[181.0,228.0,1.0,...|       15.34|\n",
      "|[129.0,263.0,2.0,...|       25.05|\n",
      "|[210.0,150.0,1.0,...|        11.3|\n",
      "|[35.0,39.0,1.0,3....|        14.8|\n",
      "|[25.0,61.0,1.0,2....|        12.3|\n",
      "|[225.0,89.0,1.0,4...|        21.8|\n",
      "|[129.0,129.0,1.0,...|         6.8|\n",
      "|[129.0,83.0,1.0,0...|         6.8|\n",
      "|[82.0,173.0,1.0,1...|        10.8|\n",
      "|[74.0,69.0,1.0,3....|        15.3|\n",
      "|[74.0,41.0,1.0,1....|         7.8|\n",
      "|[41.0,127.0,1.0,5...|        20.3|\n",
      "|[7.0,260.0,1.0,1....|        10.8|\n",
      "|[7.0,7.0,1.0,1.42...|         8.3|\n",
      "|[7.0,133.0,1.0,15...|       53.16|\n",
      "|[134.0,28.0,1.0,1...|         7.8|\n",
      "|[89.0,39.0,1.0,2....|        11.3|\n",
      "|[66.0,65.0,3.0,1....|         7.8|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "901b3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd8c05f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      total_amount|\n",
      "+-------+------------------+\n",
      "|  count|                67|\n",
      "|   mean|15.569701492537295|\n",
      "| stddev| 9.920033750270859|\n",
      "|    min|               4.8|\n",
      "|    max|             53.16|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "291a4323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      total_amount|\n",
      "+-------+------------------+\n",
      "|  count|                31|\n",
      "|   mean|17.497419354838712|\n",
      "| stddev|15.890901373163604|\n",
      "|    min|               4.8|\n",
      "|    max|              78.1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad20f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol=\"total_amount\")\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821cd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "439f818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\spark-3.2.1-bin-hadoop3.2\\python\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  1.1156543055488335|\n",
      "|2.856515024518558E-7|\n",
      "|1.020307571764078...|\n",
      "|  -0.572135291787589|\n",
      "|1.181408038064546...|\n",
      "|1.204721709058276...|\n",
      "|1.097926105586566...|\n",
      "|-3.00240863282397...|\n",
      "| 9.72314833092014E-8|\n",
      "|1.293392513090907...|\n",
      "|-2.66408530791295...|\n",
      "|5.384456081003463...|\n",
      "| -0.7437696236711648|\n",
      "| -0.5721315556215458|\n",
      "|4.242300040147029E-7|\n",
      "|7.688969994035233E-8|\n",
      "|2.537640142463715E-8|\n",
      "|3.612127308372237E-8|\n",
      "| -0.2860673466072967|\n",
      "|-2.93007900609154...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5ed4561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3319012336608198"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4d40708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995492236652422"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f77e68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      total_amount|\n",
      "+-------+------------------+\n",
      "|  count|                98|\n",
      "|   mean|16.179489795918347|\n",
      "| stddev|12.077604508545692|\n",
      "|    min|               4.8|\n",
      "|    max|              78.1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.describe().show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
